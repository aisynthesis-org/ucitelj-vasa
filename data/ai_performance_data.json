[
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750197054.6234653,
    "timestamp": "2025-06-17T23:50:54.623468",
    "duration_seconds": 3.219,
    "success": true,
    "response_length": 221,
    "error": null,
    "tokens_per_second": 68.66,
    "prompt_length": 13,
    "temperature": 0.3,
    "max_tokens": 100
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750198273.50827,
    "timestamp": "2025-06-18T00:11:13.508272",
    "duration_seconds": 2.993,
    "success": true,
    "response_length": 232,
    "error": null,
    "tokens_per_second": 77.51,
    "prompt_length": 12,
    "temperature": 0.3,
    "max_tokens": 100
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750198334.553631,
    "timestamp": "2025-06-18T00:12:14.553633",
    "duration_seconds": 0.558,
    "success": true,
    "response_length": 7,
    "error": null,
    "tokens_per_second": 12.54,
    "prompt_length": 25,
    "temperature": 0.3,
    "max_tokens": 100
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash",
    "operation": "generate_content",
    "start_time": 1750198369.3047862,
    "timestamp": "2025-06-18T00:12:49.304787",
    "duration_seconds": 1.318,
    "success": true,
    "response_length": 7,
    "error": null,
    "tokens_per_second": 5.31,
    "prompt_length": 25,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash",
    "operation": "generate_content",
    "start_time": 1750198381.5920925,
    "timestamp": "2025-06-18T00:13:01.592093",
    "duration_seconds": 0.634,
    "success": true,
    "response_length": 114,
    "error": null,
    "tokens_per_second": 179.83,
    "prompt_length": 766,
    "temperature": 0.3,
    "max_tokens": 100
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash",
    "operation": "generate_content",
    "start_time": 1750198507.3653693,
    "timestamp": "2025-06-18T00:15:07.365371",
    "duration_seconds": 1.211,
    "success": true,
    "response_length": 334,
    "error": null,
    "tokens_per_second": 275.79,
    "prompt_length": 720,
    "temperature": 0.3,
    "max_tokens": 100
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750198546.4311647,
    "timestamp": "2025-06-18T00:15:46.431167",
    "duration_seconds": 3.594,
    "success": true,
    "response_length": 540,
    "error": null,
    "tokens_per_second": 150.23,
    "prompt_length": 14,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750198550.2541928,
    "timestamp": "2025-06-18T00:15:50.254194",
    "duration_seconds": 4.432,
    "success": true,
    "response_length": 962,
    "error": null,
    "tokens_per_second": 217.05,
    "prompt_length": 14,
    "temperature": 0.2,
    "max_tokens": 400
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash",
    "operation": "generate_content",
    "start_time": 1750198554.6871397,
    "timestamp": "2025-06-18T00:15:54.687140",
    "duration_seconds": 1.466,
    "success": true,
    "response_length": 507,
    "error": null,
    "tokens_per_second": 345.84,
    "prompt_length": 14,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash",
    "operation": "generate_content",
    "start_time": 1750198556.1538494,
    "timestamp": "2025-06-18T00:15:56.153849",
    "duration_seconds": 2.767,
    "success": true,
    "response_length": 1448,
    "error": null,
    "tokens_per_second": 523.26,
    "prompt_length": 14,
    "temperature": 0.2,
    "max_tokens": 400
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750198559.6518104,
    "timestamp": "2025-06-18T00:15:59.651811",
    "duration_seconds": 1.204,
    "success": true,
    "response_length": 12,
    "error": null,
    "tokens_per_second": 9.97,
    "prompt_length": 18,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750198561.0838408,
    "timestamp": "2025-06-18T00:16:01.083842",
    "duration_seconds": 0.581,
    "success": true,
    "response_length": 12,
    "error": null,
    "tokens_per_second": 20.64,
    "prompt_length": 18,
    "temperature": 0.3,
    "max_tokens": 100
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash",
    "operation": "generate_content",
    "start_time": 1750198561.666324,
    "timestamp": "2025-06-18T00:16:01.666324",
    "duration_seconds": 0.887,
    "success": true,
    "response_length": 12,
    "error": null,
    "tokens_per_second": 13.53,
    "prompt_length": 18,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash",
    "operation": "generate_content",
    "start_time": 1750198562.5541422,
    "timestamp": "2025-06-18T00:16:02.554142",
    "duration_seconds": 0.743,
    "success": true,
    "response_length": 12,
    "error": null,
    "tokens_per_second": 16.15,
    "prompt_length": 18,
    "temperature": 0.3,
    "max_tokens": 100
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750198564.0544705,
    "timestamp": "2025-06-18T00:16:04.054472",
    "duration_seconds": 0.368,
    "success": true,
    "response_length": 30,
    "error": null,
    "tokens_per_second": 81.49,
    "prompt_length": 27,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750198564.6578674,
    "timestamp": "2025-06-18T00:16:04.657869",
    "duration_seconds": 1.085,
    "success": true,
    "response_length": 30,
    "error": null,
    "tokens_per_second": 27.65,
    "prompt_length": 27,
    "temperature": 0.4,
    "max_tokens": 200
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash",
    "operation": "generate_content",
    "start_time": 1750198565.7438426,
    "timestamp": "2025-06-18T00:16:05.743842",
    "duration_seconds": 0.849,
    "success": true,
    "response_length": 30,
    "error": null,
    "tokens_per_second": 35.34,
    "prompt_length": 27,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash",
    "operation": "generate_content",
    "start_time": 1750198566.5935795,
    "timestamp": "2025-06-18T00:16:06.593580",
    "duration_seconds": 0.47,
    "success": true,
    "response_length": 34,
    "error": null,
    "tokens_per_second": 72.28,
    "prompt_length": 27,
    "temperature": 0.4,
    "max_tokens": 200
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750198567.795184,
    "timestamp": "2025-06-18T00:16:07.795186",
    "duration_seconds": 3.973,
    "success": true,
    "response_length": 474,
    "error": null,
    "tokens_per_second": 119.31,
    "prompt_length": 50,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750198571.9987977,
    "timestamp": "2025-06-18T00:16:11.998798",
    "duration_seconds": 2.988,
    "success": true,
    "response_length": 488,
    "error": null,
    "tokens_per_second": 163.32,
    "prompt_length": 50,
    "temperature": 0.2,
    "max_tokens": 400
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash",
    "operation": "generate_content",
    "start_time": 1750198574.9879036,
    "timestamp": "2025-06-18T00:16:14.987903",
    "duration_seconds": 1.414,
    "success": true,
    "response_length": 434,
    "error": null,
    "tokens_per_second": 307.04,
    "prompt_length": 50,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash",
    "operation": "generate_content",
    "start_time": 1750198576.4026418,
    "timestamp": "2025-06-18T00:16:16.402642",
    "duration_seconds": 2.684,
    "success": true,
    "response_length": 1108,
    "error": null,
    "tokens_per_second": 412.74,
    "prompt_length": 50,
    "temperature": 0.2,
    "max_tokens": 400
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750198579.8199725,
    "timestamp": "2025-06-18T00:16:19.819974",
    "duration_seconds": 3.594,
    "success": true,
    "response_length": 414,
    "error": null,
    "tokens_per_second": 115.18,
    "prompt_length": 34,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750198583.6466932,
    "timestamp": "2025-06-18T00:16:23.646694",
    "duration_seconds": 7.176,
    "success": true,
    "response_length": 1125,
    "error": null,
    "tokens_per_second": 156.77,
    "prompt_length": 34,
    "temperature": 0.2,
    "max_tokens": 400
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash",
    "operation": "generate_content",
    "start_time": 1750198590.824098,
    "timestamp": "2025-06-18T00:16:30.824098",
    "duration_seconds": 1.467,
    "success": true,
    "response_length": 429,
    "error": null,
    "tokens_per_second": 292.37,
    "prompt_length": 34,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash",
    "operation": "generate_content",
    "start_time": 1750198592.2923732,
    "timestamp": "2025-06-18T00:16:32.292373",
    "duration_seconds": 2.403,
    "success": true,
    "response_length": 1022,
    "error": null,
    "tokens_per_second": 425.32,
    "prompt_length": 34,
    "temperature": 0.2,
    "max_tokens": 400
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750198595.4278378,
    "timestamp": "2025-06-18T00:16:35.427839",
    "duration_seconds": 3.012,
    "success": true,
    "response_length": 448,
    "error": null,
    "tokens_per_second": 148.76,
    "prompt_length": 35,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750198598.6698627,
    "timestamp": "2025-06-18T00:16:38.669864",
    "duration_seconds": 7.41,
    "success": true,
    "response_length": 1440,
    "error": null,
    "tokens_per_second": 194.34,
    "prompt_length": 35,
    "temperature": 0.7,
    "max_tokens": 500
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash",
    "operation": "generate_content",
    "start_time": 1750198606.0804834,
    "timestamp": "2025-06-18T00:16:46.080483",
    "duration_seconds": 1.553,
    "success": true,
    "response_length": 508,
    "error": null,
    "tokens_per_second": 327.2,
    "prompt_length": 35,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash",
    "operation": "generate_content",
    "start_time": 1750198607.6341014,
    "timestamp": "2025-06-18T00:16:47.634101",
    "duration_seconds": 3.11,
    "success": true,
    "response_length": 1518,
    "error": null,
    "tokens_per_second": 488.11,
    "prompt_length": 35,
    "temperature": 0.7,
    "max_tokens": 500
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750198611.4743173,
    "timestamp": "2025-06-18T00:16:51.474318",
    "duration_seconds": 2.255,
    "success": true,
    "response_length": 506,
    "error": null,
    "tokens_per_second": 224.41,
    "prompt_length": 37,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750198613.9605546,
    "timestamp": "2025-06-18T00:16:53.960556",
    "duration_seconds": 5.417,
    "success": true,
    "response_length": 1417,
    "error": null,
    "tokens_per_second": 261.59,
    "prompt_length": 37,
    "temperature": 0.7,
    "max_tokens": 500
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash",
    "operation": "generate_content",
    "start_time": 1750198619.3786771,
    "timestamp": "2025-06-18T00:16:59.378677",
    "duration_seconds": 1.188,
    "success": true,
    "response_length": 464,
    "error": null,
    "tokens_per_second": 390.56,
    "prompt_length": 37,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash",
    "operation": "generate_content",
    "start_time": 1750198620.567897,
    "timestamp": "2025-06-18T00:17:00.567897",
    "duration_seconds": 3.338,
    "success": true,
    "response_length": 1425,
    "error": null,
    "tokens_per_second": 426.89,
    "prompt_length": 37,
    "temperature": 0.7,
    "max_tokens": 500
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750198624.6524444,
    "timestamp": "2025-06-18T00:17:04.652446",
    "duration_seconds": 2.73,
    "success": true,
    "response_length": 509,
    "error": null,
    "tokens_per_second": 186.42,
    "prompt_length": 55,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750198627.6174366,
    "timestamp": "2025-06-18T00:17:07.617438",
    "duration_seconds": 1.604,
    "success": true,
    "response_length": 335,
    "error": null,
    "tokens_per_second": 208.87,
    "prompt_length": 55,
    "temperature": 0.3,
    "max_tokens": 100
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash",
    "operation": "generate_content",
    "start_time": 1750198629.2225404,
    "timestamp": "2025-06-18T00:17:09.222540",
    "duration_seconds": 1.403,
    "success": true,
    "response_length": 519,
    "error": null,
    "tokens_per_second": 369.89,
    "prompt_length": 55,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash",
    "operation": "generate_content",
    "start_time": 1750198630.626881,
    "timestamp": "2025-06-18T00:17:10.626881",
    "duration_seconds": 1.086,
    "success": true,
    "response_length": 347,
    "error": null,
    "tokens_per_second": 319.64,
    "prompt_length": 55,
    "temperature": 0.3,
    "max_tokens": 100
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750198632.4458792,
    "timestamp": "2025-06-18T00:17:12.445881",
    "duration_seconds": 4.495,
    "success": true,
    "response_length": 545,
    "error": null,
    "tokens_per_second": 121.24,
    "prompt_length": 47,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750198637.1701555,
    "timestamp": "2025-06-18T00:17:17.170157",
    "duration_seconds": 6.526,
    "success": true,
    "response_length": 1407,
    "error": null,
    "tokens_per_second": 215.6,
    "prompt_length": 47,
    "temperature": 0.2,
    "max_tokens": 400
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash",
    "operation": "generate_content",
    "start_time": 1750198643.6974156,
    "timestamp": "2025-06-18T00:17:23.697416",
    "duration_seconds": 1.436,
    "success": true,
    "response_length": 542,
    "error": null,
    "tokens_per_second": 377.31,
    "prompt_length": 47,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash",
    "operation": "generate_content",
    "start_time": 1750198645.1352994,
    "timestamp": "2025-06-18T00:17:25.135299",
    "duration_seconds": 2.634,
    "success": true,
    "response_length": 1368,
    "error": null,
    "tokens_per_second": 519.38,
    "prompt_length": 47,
    "temperature": 0.2,
    "max_tokens": 400
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750198648.498286,
    "timestamp": "2025-06-18T00:17:28.498287",
    "duration_seconds": 3.206,
    "success": true,
    "response_length": 518,
    "error": null,
    "tokens_per_second": 161.6,
    "prompt_length": 42,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750198651.9355373,
    "timestamp": "2025-06-18T00:17:31.935539",
    "duration_seconds": 4.369,
    "success": true,
    "response_length": 932,
    "error": null,
    "tokens_per_second": 213.3,
    "prompt_length": 42,
    "temperature": 0.2,
    "max_tokens": 400
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash",
    "operation": "generate_content",
    "start_time": 1750198656.3064117,
    "timestamp": "2025-06-18T00:17:36.306412",
    "duration_seconds": 1.679,
    "success": true,
    "response_length": 465,
    "error": null,
    "tokens_per_second": 276.93,
    "prompt_length": 42,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash",
    "operation": "generate_content",
    "start_time": 1750198657.9869578,
    "timestamp": "2025-06-18T00:17:37.986958",
    "duration_seconds": 3.376,
    "success": true,
    "response_length": 1289,
    "error": null,
    "tokens_per_second": 381.83,
    "prompt_length": 42,
    "temperature": 0.2,
    "max_tokens": 400
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750198662.091421,
    "timestamp": "2025-06-18T00:17:42.091423",
    "duration_seconds": 2.953,
    "success": true,
    "response_length": 460,
    "error": null,
    "tokens_per_second": 155.76,
    "prompt_length": 41,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750198665.2745986,
    "timestamp": "2025-06-18T00:17:45.274600",
    "duration_seconds": 6.793,
    "success": true,
    "response_length": 999,
    "error": null,
    "tokens_per_second": 147.05,
    "prompt_length": 41,
    "temperature": 1.2,
    "max_tokens": 600
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash",
    "operation": "generate_content",
    "start_time": 1750198672.069542,
    "timestamp": "2025-06-18T00:17:52.069542",
    "duration_seconds": 1.678,
    "success": true,
    "response_length": 512,
    "error": null,
    "tokens_per_second": 305.07,
    "prompt_length": 41,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash",
    "operation": "generate_content",
    "start_time": 1750198673.749168,
    "timestamp": "2025-06-18T00:17:53.749168",
    "duration_seconds": 3.639,
    "success": true,
    "response_length": 1731,
    "error": null,
    "tokens_per_second": 475.63,
    "prompt_length": 41,
    "temperature": 1.2,
    "max_tokens": 600
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750198678.121714,
    "timestamp": "2025-06-18T00:17:58.121715",
    "duration_seconds": 2.572,
    "success": true,
    "response_length": 574,
    "error": null,
    "tokens_per_second": 223.18,
    "prompt_length": 29,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750198680.9353588,
    "timestamp": "2025-06-18T00:18:00.935361",
    "duration_seconds": 1.793,
    "success": true,
    "response_length": 364,
    "error": null,
    "tokens_per_second": 202.99,
    "prompt_length": 29,
    "temperature": 0.3,
    "max_tokens": 100
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash",
    "operation": "generate_content",
    "start_time": 1750198682.7312927,
    "timestamp": "2025-06-18T00:18:02.731293",
    "duration_seconds": 1.421,
    "success": true,
    "response_length": 489,
    "error": null,
    "tokens_per_second": 344.07,
    "prompt_length": 29,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash",
    "operation": "generate_content",
    "start_time": 1750198684.1539414,
    "timestamp": "2025-06-18T00:18:04.153942",
    "duration_seconds": 0.997,
    "success": true,
    "response_length": 326,
    "error": null,
    "tokens_per_second": 327.13,
    "prompt_length": 29,
    "temperature": 0.3,
    "max_tokens": 100
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash",
    "operation": "generate_content",
    "start_time": 1750200067.825528,
    "timestamp": "2025-06-18T00:41:07.825530",
    "duration_seconds": 0.344,
    "success": true,
    "response_length": 7,
    "error": null,
    "tokens_per_second": 20.33,
    "prompt_length": 25,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash",
    "operation": "generate_content",
    "start_time": 1750200233.334074,
    "timestamp": "2025-06-18T00:43:53.334076",
    "duration_seconds": 0.289,
    "success": true,
    "response_length": 7,
    "error": null,
    "tokens_per_second": 24.18,
    "prompt_length": 25,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash",
    "operation": "generate_content",
    "start_time": 1750200398.6739218,
    "timestamp": "2025-06-18T00:46:38.673924",
    "duration_seconds": 0.907,
    "success": true,
    "response_length": 194,
    "error": null,
    "tokens_per_second": 213.95,
    "prompt_length": 715,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash",
    "operation": "generate_content",
    "start_time": 1750200454.0405242,
    "timestamp": "2025-06-18T00:47:34.040526",
    "duration_seconds": 0.56,
    "success": true,
    "response_length": 116,
    "error": null,
    "tokens_per_second": 207.24,
    "prompt_length": 788,
    "temperature": 0.3,
    "max_tokens": 100
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash",
    "operation": "generate_content",
    "start_time": 1750200454.6017995,
    "timestamp": "2025-06-18T00:47:34.601801",
    "duration_seconds": 0.944,
    "success": true,
    "response_length": 238,
    "error": null,
    "tokens_per_second": 252.1,
    "prompt_length": 805,
    "temperature": 0.7,
    "max_tokens": 500
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750205721.4108894,
    "timestamp": "2025-06-18T02:15:21.410889",
    "duration_seconds": 3.929,
    "success": true,
    "response_length": 507,
    "error": null,
    "tokens_per_second": 129.02,
    "prompt_length": 14,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750205726.3422556,
    "timestamp": "2025-06-18T02:15:26.342256",
    "duration_seconds": 5.142,
    "success": true,
    "response_length": 517,
    "error": null,
    "tokens_per_second": 100.55,
    "prompt_length": 14,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750205732.485662,
    "timestamp": "2025-06-18T02:15:32.485662",
    "duration_seconds": 6.496,
    "success": true,
    "response_length": 517,
    "error": null,
    "tokens_per_second": 79.59,
    "prompt_length": 14,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750205739.983761,
    "timestamp": "2025-06-18T02:15:39.983761",
    "duration_seconds": 2.309,
    "success": true,
    "response_length": 496,
    "error": null,
    "tokens_per_second": 214.81,
    "prompt_length": 14,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750205743.2948291,
    "timestamp": "2025-06-18T02:15:43.294829",
    "duration_seconds": 3.606,
    "success": true,
    "response_length": 509,
    "error": null,
    "tokens_per_second": 141.17,
    "prompt_length": 14,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750205747.9021988,
    "timestamp": "2025-06-18T02:15:47.902199",
    "duration_seconds": 0.735,
    "success": true,
    "response_length": 64,
    "error": null,
    "tokens_per_second": 87.09,
    "prompt_length": 4,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750205748.6386833,
    "timestamp": "2025-06-18T02:15:48.638683",
    "duration_seconds": 0.939,
    "success": true,
    "response_length": 62,
    "error": null,
    "tokens_per_second": 66.03,
    "prompt_length": 4,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750205749.579196,
    "timestamp": "2025-06-18T02:15:49.579196",
    "duration_seconds": 0.993,
    "success": true,
    "response_length": 73,
    "error": null,
    "tokens_per_second": 73.54,
    "prompt_length": 4,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750205750.5733037,
    "timestamp": "2025-06-18T02:15:50.573304",
    "duration_seconds": 0.873,
    "success": true,
    "response_length": 71,
    "error": null,
    "tokens_per_second": 81.32,
    "prompt_length": 4,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750205751.4478912,
    "timestamp": "2025-06-18T02:15:51.447891",
    "duration_seconds": 0.844,
    "success": true,
    "response_length": 73,
    "error": null,
    "tokens_per_second": 86.48,
    "prompt_length": 4,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750205752.293447,
    "timestamp": "2025-06-18T02:15:52.293447",
    "duration_seconds": 0.928,
    "success": true,
    "response_length": 71,
    "error": null,
    "tokens_per_second": 76.49,
    "prompt_length": 4,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750205788.2238295,
    "timestamp": "2025-06-18T02:16:28.223830",
    "duration_seconds": 3.529,
    "success": true,
    "response_length": 541,
    "error": null,
    "tokens_per_second": 153.29,
    "prompt_length": 19,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750205791.75473,
    "timestamp": "2025-06-18T02:16:31.754730",
    "duration_seconds": 3.947,
    "success": true,
    "response_length": 42,
    "error": null,
    "tokens_per_second": 10.64,
    "prompt_length": 7,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750205795.703493,
    "timestamp": "2025-06-18T02:16:35.703493",
    "duration_seconds": 1.106,
    "success": true,
    "response_length": 146,
    "error": null,
    "tokens_per_second": 131.98,
    "prompt_length": 21,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750205796.8175347,
    "timestamp": "2025-06-18T02:16:36.817535",
    "duration_seconds": 3.0,
    "success": true,
    "response_length": 492,
    "error": null,
    "tokens_per_second": 163.99,
    "prompt_length": 22,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750205799.819271,
    "timestamp": "2025-06-18T02:16:39.819271",
    "duration_seconds": 1.409,
    "success": true,
    "response_length": 179,
    "error": null,
    "tokens_per_second": 127.04,
    "prompt_length": 13,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750206253.7603595,
    "timestamp": "2025-06-18T02:24:13.760360",
    "duration_seconds": 0.752,
    "success": true,
    "response_length": 7,
    "error": null,
    "tokens_per_second": 9.31,
    "prompt_length": 25,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750206746.5497427,
    "timestamp": "2025-06-18T02:32:26.549744",
    "duration_seconds": 1.767,
    "success": true,
    "response_length": 7,
    "error": null,
    "tokens_per_second": 3.96,
    "prompt_length": 25,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash",
    "operation": "generate_content",
    "start_time": 1750206756.4646187,
    "timestamp": "2025-06-18T02:32:36.464620",
    "duration_seconds": 0.486,
    "success": true,
    "response_length": 7,
    "error": null,
    "tokens_per_second": 14.4,
    "prompt_length": 25,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750206779.8726206,
    "timestamp": "2025-06-18T02:32:59.872622",
    "duration_seconds": 0.543,
    "success": true,
    "response_length": 7,
    "error": null,
    "tokens_per_second": 12.88,
    "prompt_length": 25,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750207954.5749278,
    "timestamp": "2025-06-18T02:52:34.574930",
    "duration_seconds": 1.219,
    "success": true,
    "response_length": 7,
    "error": null,
    "tokens_per_second": 5.74,
    "prompt_length": 25,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750266553.4495006,
    "timestamp": "2025-06-18T19:09:13.449502",
    "duration_seconds": 1.722,
    "success": true,
    "response_length": 7,
    "error": null,
    "tokens_per_second": 4.06,
    "prompt_length": 25,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750267708.8094614,
    "timestamp": "2025-06-18T19:28:28.809462",
    "duration_seconds": 1.672,
    "success": true,
    "response_length": 116,
    "error": null,
    "tokens_per_second": 69.38,
    "prompt_length": 25,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750267784.0242484,
    "timestamp": "2025-06-18T19:29:44.024250",
    "duration_seconds": 0.852,
    "success": true,
    "response_length": 7,
    "error": null,
    "tokens_per_second": 8.22,
    "prompt_length": 25,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750269044.4842691,
    "timestamp": "2025-06-18T19:50:44.484270",
    "duration_seconds": 1.202,
    "success": true,
    "response_length": 7,
    "error": null,
    "tokens_per_second": 5.82,
    "prompt_length": 25,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750276694.418169,
    "timestamp": "2025-06-18T21:58:14.418169",
    "duration_seconds": 3.168,
    "success": true,
    "response_length": 516,
    "error": null,
    "tokens_per_second": 162.9,
    "prompt_length": 15,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750283128.5141451,
    "timestamp": "2025-06-18T23:45:28.514146",
    "duration_seconds": 1.218,
    "success": true,
    "response_length": 7,
    "error": null,
    "tokens_per_second": 5.75,
    "prompt_length": 25,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750285672.9385839,
    "timestamp": "2025-06-19T00:27:52.938583",
    "duration_seconds": 3.623,
    "success": true,
    "response_length": 567,
    "error": null,
    "tokens_per_second": 156.5,
    "prompt_length": 15,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750287230.7438986,
    "timestamp": "2025-06-19T00:53:50.743898",
    "duration_seconds": 3.418,
    "success": true,
    "response_length": 507,
    "error": null,
    "tokens_per_second": 148.35,
    "prompt_length": 32,
    "temperature": 0.7,
    "max_tokens": 150
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750350488.1329284,
    "timestamp": "2025-06-19T18:28:08.132928",
    "duration_seconds": 4.028,
    "success": true,
    "response_length": 698,
    "error": null,
    "tokens_per_second": 173.3,
    "prompt_length": 62,
    "temperature": 0.3,
    "max_tokens": 300
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750350494.218602,
    "timestamp": "2025-06-19T18:28:14.218602",
    "duration_seconds": 4.739,
    "success": true,
    "response_length": 733,
    "error": null,
    "tokens_per_second": 154.67,
    "prompt_length": 34,
    "temperature": 0.2,
    "max_tokens": 250
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750350500.9881542,
    "timestamp": "2025-06-19T18:28:20.988154",
    "duration_seconds": 5.295,
    "success": true,
    "response_length": 1262,
    "error": null,
    "tokens_per_second": 238.33,
    "prompt_length": 27,
    "temperature": 0.6,
    "max_tokens": 400
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750350508.3325038,
    "timestamp": "2025-06-19T18:28:28.332503",
    "duration_seconds": 1.02,
    "success": true,
    "response_length": 82,
    "error": null,
    "tokens_per_second": 80.37,
    "prompt_length": 16,
    "temperature": 0.6,
    "max_tokens": 400
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750350513.4412923,
    "timestamp": "2025-06-19T18:28:33.441292",
    "duration_seconds": 5.19,
    "success": true,
    "response_length": 1088,
    "error": null,
    "tokens_per_second": 209.63,
    "prompt_length": 30,
    "temperature": 0.6,
    "max_tokens": 400
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750350524.7694862,
    "timestamp": "2025-06-19T18:28:44.769486",
    "duration_seconds": 1.807,
    "success": true,
    "response_length": 435,
    "error": null,
    "tokens_per_second": 240.78,
    "prompt_length": 26,
    "temperature": 0.3,
    "max_tokens": 300
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750350530.6517868,
    "timestamp": "2025-06-19T18:28:50.651787",
    "duration_seconds": 1.806,
    "success": true,
    "response_length": 447,
    "error": null,
    "tokens_per_second": 247.49,
    "prompt_length": 26,
    "temperature": 0.3,
    "max_tokens": 300
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750350536.511158,
    "timestamp": "2025-06-19T18:28:56.511158",
    "duration_seconds": 1.763,
    "success": true,
    "response_length": 452,
    "error": null,
    "tokens_per_second": 256.38,
    "prompt_length": 26,
    "temperature": 0.3,
    "max_tokens": 300
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750350542.3773818,
    "timestamp": "2025-06-19T18:29:02.377382",
    "duration_seconds": 3.377,
    "success": true,
    "response_length": 619,
    "error": null,
    "tokens_per_second": 183.33,
    "prompt_length": 23,
    "temperature": 0.6,
    "max_tokens": 400
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750350547.790691,
    "timestamp": "2025-06-19T18:29:07.790691",
    "duration_seconds": 3.149,
    "success": true,
    "response_length": 795,
    "error": null,
    "tokens_per_second": 252.43,
    "prompt_length": 28,
    "temperature": 0.3,
    "max_tokens": 300
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750350552.958266,
    "timestamp": "2025-06-19T18:29:12.958266",
    "duration_seconds": 0.783,
    "success": true,
    "response_length": 55,
    "error": null,
    "tokens_per_second": 70.25,
    "prompt_length": 14,
    "temperature": 0.2,
    "max_tokens": 250
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750350555.781773,
    "timestamp": "2025-06-19T18:29:15.781773",
    "duration_seconds": 5.553,
    "success": true,
    "response_length": 1381,
    "error": null,
    "tokens_per_second": 248.71,
    "prompt_length": 15,
    "temperature": 0.6,
    "max_tokens": 400
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750350563.3623884,
    "timestamp": "2025-06-19T18:29:23.362388",
    "duration_seconds": 0.816,
    "success": true,
    "response_length": 36,
    "error": null,
    "tokens_per_second": 44.09,
    "prompt_length": 7,
    "temperature": 0.8,
    "max_tokens": 100
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750351289.1059186,
    "timestamp": "2025-06-19T18:41:29.105919",
    "duration_seconds": 3.13,
    "success": true,
    "response_length": 693,
    "error": null,
    "tokens_per_second": 221.4,
    "prompt_length": 62,
    "temperature": 0.3,
    "max_tokens": 300
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750351294.281285,
    "timestamp": "2025-06-19T18:41:34.281285",
    "duration_seconds": 2.887,
    "success": true,
    "response_length": 531,
    "error": null,
    "tokens_per_second": 183.92,
    "prompt_length": 34,
    "temperature": 0.2,
    "max_tokens": 250
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750351299.2167778,
    "timestamp": "2025-06-19T18:41:39.216778",
    "duration_seconds": 10.207,
    "success": true,
    "response_length": 1269,
    "error": null,
    "tokens_per_second": 124.32,
    "prompt_length": 27,
    "temperature": 0.6,
    "max_tokens": 400
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750351311.4618554,
    "timestamp": "2025-06-19T18:41:51.461855",
    "duration_seconds": 0.816,
    "success": true,
    "response_length": 82,
    "error": null,
    "tokens_per_second": 100.54,
    "prompt_length": 16,
    "temperature": 0.6,
    "max_tokens": 400
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750351316.3755553,
    "timestamp": "2025-06-19T18:41:56.375555",
    "duration_seconds": 5.205,
    "success": true,
    "response_length": 1081,
    "error": null,
    "tokens_per_second": 207.67,
    "prompt_length": 30,
    "temperature": 0.6,
    "max_tokens": 400
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750351327.7088947,
    "timestamp": "2025-06-19T18:42:07.708894",
    "duration_seconds": 1.382,
    "success": true,
    "response_length": 435,
    "error": null,
    "tokens_per_second": 314.86,
    "prompt_length": 26,
    "temperature": 0.3,
    "max_tokens": 300
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750351333.182084,
    "timestamp": "2025-06-19T18:42:13.182084",
    "duration_seconds": 1.697,
    "success": true,
    "response_length": 464,
    "error": null,
    "tokens_per_second": 273.36,
    "prompt_length": 26,
    "temperature": 0.3,
    "max_tokens": 300
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750351338.9735463,
    "timestamp": "2025-06-19T18:42:18.973546",
    "duration_seconds": 1.58,
    "success": true,
    "response_length": 446,
    "error": null,
    "tokens_per_second": 282.31,
    "prompt_length": 26,
    "temperature": 0.3,
    "max_tokens": 300
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750351344.6446028,
    "timestamp": "2025-06-19T18:42:24.644603",
    "duration_seconds": 6.079,
    "success": true,
    "response_length": 937,
    "error": null,
    "tokens_per_second": 154.13,
    "prompt_length": 23,
    "temperature": 0.6,
    "max_tokens": 400
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750351352.7612453,
    "timestamp": "2025-06-19T18:42:32.761245",
    "duration_seconds": 3.762,
    "success": true,
    "response_length": 920,
    "error": null,
    "tokens_per_second": 244.57,
    "prompt_length": 28,
    "temperature": 0.3,
    "max_tokens": 300
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750351358.5681148,
    "timestamp": "2025-06-19T18:42:38.568115",
    "duration_seconds": 0.821,
    "success": true,
    "response_length": 55,
    "error": null,
    "tokens_per_second": 66.99,
    "prompt_length": 14,
    "temperature": 0.2,
    "max_tokens": 250
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750351361.4321828,
    "timestamp": "2025-06-19T18:42:41.432183",
    "duration_seconds": 6.163,
    "success": true,
    "response_length": 1353,
    "error": null,
    "tokens_per_second": 219.53,
    "prompt_length": 15,
    "temperature": 0.6,
    "max_tokens": 400
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750351369.6365268,
    "timestamp": "2025-06-19T18:42:49.636527",
    "duration_seconds": 0.562,
    "success": true,
    "response_length": 42,
    "error": null,
    "tokens_per_second": 74.71,
    "prompt_length": 7,
    "temperature": 0.8,
    "max_tokens": 100
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750356352.9776704,
    "timestamp": "2025-06-19T20:05:52.977670",
    "duration_seconds": 13.846,
    "success": true,
    "response_length": 1270,
    "error": null,
    "tokens_per_second": 91.72,
    "prompt_length": 34,
    "temperature": 0.5,
    "max_tokens": 600
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750356475.0494246,
    "timestamp": "2025-06-19T20:07:55.049425",
    "duration_seconds": 31.941,
    "success": true,
    "response_length": 10153,
    "error": null,
    "tokens_per_second": 317.87,
    "prompt_length": 14,
    "temperature": 2.0,
    "max_tokens": 2000
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750356557.25554,
    "timestamp": "2025-06-19T20:09:17.255540",
    "duration_seconds": 27.652,
    "success": true,
    "response_length": 10323,
    "error": null,
    "tokens_per_second": 373.32,
    "prompt_length": 14,
    "temperature": 2.0,
    "max_tokens": 2000
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750356602.691514,
    "timestamp": "2025-06-19T20:10:02.691514",
    "duration_seconds": 10.523,
    "success": true,
    "response_length": 891,
    "error": null,
    "tokens_per_second": 84.67,
    "prompt_length": 14,
    "temperature": 0.0,
    "max_tokens": 2000
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750356640.4776213,
    "timestamp": "2025-06-19T20:10:40.477621",
    "duration_seconds": 6.093,
    "success": true,
    "response_length": 1039,
    "error": null,
    "tokens_per_second": 170.52,
    "prompt_length": 14,
    "temperature": 1.0,
    "max_tokens": 2000
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750356687.8481965,
    "timestamp": "2025-06-19T20:11:27.848197",
    "duration_seconds": 6.181,
    "success": true,
    "response_length": 1357,
    "error": null,
    "tokens_per_second": 219.55,
    "prompt_length": 14,
    "temperature": 1.2,
    "max_tokens": 2000
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750356752.1205516,
    "timestamp": "2025-06-19T20:12:32.120552",
    "duration_seconds": 39.103,
    "success": true,
    "response_length": 9919,
    "error": null,
    "tokens_per_second": 253.66,
    "prompt_length": 14,
    "temperature": 2.0,
    "max_tokens": 2000
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750356837.651931,
    "timestamp": "2025-06-19T20:13:57.651931",
    "duration_seconds": 62.603,
    "success": true,
    "response_length": 10718,
    "error": null,
    "tokens_per_second": 171.21,
    "prompt_length": 14,
    "temperature": 1.9,
    "max_tokens": 2000
  },
  {
    "provider": "openai",
    "model": "gpt-4.1",
    "operation": "chat_completion",
    "start_time": 1750356929.8685935,
    "timestamp": "2025-06-19T20:15:29.868594",
    "duration_seconds": 7.971,
    "success": true,
    "response_length": 1287,
    "error": null,
    "tokens_per_second": 161.45,
    "prompt_length": 14,
    "temperature": 1.5,
    "max_tokens": 500
  }
]